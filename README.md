# Trabajos Pr谩cticos de Procesamiento de Lenguaje Natural 1 (PLN1)

Este repo contiene las soluciones a una serie de desaf铆os pr谩cticos del curso de Procesamiento de Lenguaje Natural 1. El proyecto abarca desde tareas de clasificaci贸n de texto y creaci贸n de embeddings hasta la generaci贸n de texto y el desarrollo de un chatbot conversacional.

Cada desaf铆o se encuentra en su propio Jupyter Notebook, donde se detalla el proceso de an谩lisis, preprocesamiento, modelado y evaluaci贸n.

##  Tecnolog铆as Utilizadas

El proyecto fue desarrollado utilizando las siguientes librer铆as y frameworks:

* **Python 3**
* **TensorFlow / Keras:** Para la construcci贸n de modelos de redes neuronales.
* **Scikit-learn:** Para modelos de clasificaci贸n cl谩sicos y m茅tricas de evaluaci贸n.
* **Gensim:** Para la creaci贸n y an谩lisis de embeddings de palabras (Word2Vec).
* **NLTK:** Para tareas de preprocesamiento de texto como tokenizaci贸n y lematizaci贸n.
* **Pandas:** Para la manipulaci贸n y an谩lisis de datos.
* **Plotly y Matplotlib/Seaborn:** Para la visualizaci贸n de datos y resultados.
* **Google Colab:** Como entorno de ejecuci贸n principal.

##  Desaf铆os Resueltos

A continuaci贸n se describe cada uno de los trabajos pr谩cticos incluidos en este proyecto:

### [Desaf铆o 1: Clasificaci贸n de Texto con Naive Bayes y Similitud TF-IDF](./Desafio1/Jose_Perez_19co_PLN_Desafio_1.ipynb)

* **Objetivo:** Explorar t茅cnicas de vectorizaci贸n TF-IDF para clasificaci贸n de texto y an谩lisis de similitud.
* **Dataset:** `20 Newsgroups`, un corpus cl谩sico con 20 categor铆as de noticias.
* **T茅cnicas Clave:**
    * Vectorizaci贸n de documentos usando **TF-IDF**.
    * An谩lisis de similitud entre documentos y palabras mediante **similitud de coseno**.
    * Entrenamiento y optimizaci贸n de modelos de clasificaci贸n **Naive Bayes (Multinomial y Complement)**, evaluando diferentes configuraciones de n-gramas y filtrado de frecuencia.

### [Desaf铆o 2: Creaci贸n de Embeddings con Gensim (Word2Vec)](./Desafio2/Jose_Perez_19co_PLN_Desafio_2.ipynb)

* **Objetivo:** Entrenar un modelo de embeddings de palabras desde cero utilizando un corpus en espa帽ol.
* **Dataset:** Noticias de los diarios *La Raz贸n* y *P煤blico* de Espa帽a.
* **T茅cnicas Clave:**
    * Preprocesamiento avanzado de texto en espa帽ol (limpieza, tokenizaci贸n, lematizaci贸n).
    * Entrenamiento de un modelo **Word2Vec (Skip-gram)** con Gensim.
    * Evaluaci贸n de la calidad de los embeddings mediante pruebas de **similitud de palabras y analog铆as** (ej. "rey - hombre + mujer = reina").
    * Visualizaci贸n del espacio vectorial de palabras con **t-SNE**.

### [Desaf铆o 3: Modelo de Lenguaje a Nivel de Caracter con RNNs](./Desafio3/Jose_Perez_19co_PLN_Desafio_3.ipynb)

* **Objetivo:** Construir un modelo de lenguaje generativo a nivel de caracter para crear texto nuevo.
* **Dataset:** El texto completo de la obra *Don Quijote de la Mancha*.
* **T茅cnicas Clave:**
    * Tokenizaci贸n a nivel de caracter.
    * Implementaci贸n de arquitecturas de **Redes Neuronales Recurrentes (SimpleRNN y LSTM)**.
    * Entrenamiento del modelo para predecir el siguiente caracter en una secuencia.
    * Generaci贸n de texto nuevo utilizando diferentes estrategias de decodificaci贸n:
        * **Greedy Search**.
        * **Beam Search (Determinista y Estoc谩stico)**, explorando el efecto de la **temperatura** para controlar la creatividad del texto.

### [Desaf铆o 4: Chatbot Conversacional con Seq2Seq y LSTMs](./Desafio4/Jose_Perez_19co_PLN_Desafio_4.ipynb)

* **Objetivo:** Desarrollar un bot conversacional (QA Bot) capaz de generar respuestas a preguntas usando una arquitectura Encoder-Decoder.
* **Dataset:** Corpus de conversaciones en ingl茅s del challenge `ConvAI2`.
* **T茅cnicas Clave:**
    * Arquitectura **Sequence-to-Sequence (Seq2Seq)** con LSTMs.
    * Modelo **Encoder-Decoder** para mapear secuencias de entrada (preguntas) a secuencias de salida (respuestas).
    * Uso de **embeddings pre-entrenados (FastText)** para mejorar la representaci贸n sem谩ntica de las palabras.
    * Implementaci贸n de un bucle de **inferencia** para generar respuestas a nuevas entradas de texto.

## 锔 C贸mo Ejecutar el Proyecto

Para explorar los notebooks y ejecutar el c贸digo:

### Instalaci贸n y Ejecuci贸n

1.  **Google Colab**
    Dado que el proyecto fue desarrollado en Colab, la forma m谩s sencilla de ejecutarlo es subir cada archivo `.ipynb` a tu Google Drive, abrirlo con Google Colaboratory y ejecutarlo directamente, aprovechando las GPUs gratuitas.

##  Autor

* **Jos茅 P茅rez** - [joseperez190498@gmail.com](mailto:joseperez190498@gmail.com)
